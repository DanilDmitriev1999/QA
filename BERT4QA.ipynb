{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT4QA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAMLcR9gvKvZ"
      },
      "source": [
        "# Техническая часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoZ9DKTvBwe",
        "outputId": "b0813190-ee61-4e68-a472-46dcb884bfd4"
      },
      "source": [
        "!pip install -q sentencepiece\n",
        "import sentencepiece\n",
        "!pip install -q transformers\n",
        "\n",
        "!pip install -q comet_ml\n",
        "import comet_ml\n",
        "!pip install -q pytorch-lightning\n",
        "\n",
        "!git clone -q https://github.com/DanilDmitriev1999/QA"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.2MB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 50.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 522kB 15.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[?25h  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 849kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 29.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 12.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 24.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 53.2MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_wCFabavQQ_",
        "outputId": "3942fe17-c1b0-41ee-dc95-d9aa06107d38"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import comet_ml\n",
        "\n",
        "import numpy as np\n",
        "import collections\n",
        "import functools\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import re\n",
        "\n",
        "from io import open\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from typing import List\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AdamW, AutoTokenizer, AutoModel\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import CometLogger\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "\n",
        "from QA.DataModule.dataset import *\n",
        "from QA.DataModule.reader import *\n",
        "\n",
        "from QA.model.BERT import *\n",
        "from QA.utils.trainer import *\n",
        "\n",
        "seed_everything(294)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cuda':\n",
        "    from torch.cuda import LongTensor\n",
        "else:\n",
        "    from torch import LongTensor\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 294\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48SuI1ciwe2F"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW5kymFKwVHd"
      },
      "source": [
        "train_file_path = '/content/QA/data/sber_squad/train-v1.1.json'\n",
        "dev_file_path = '/content/QA/data/sber_squad/dev-v1.1.json'\n",
        "train = ReadData(train_file_path)\n",
        "train_data = train.data\n",
        "dev = ReadData(dev_file_path)\n",
        "dev_data = dev.data\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGcmL7UjwkiP"
      },
      "source": [
        "def collate_fn(examples):\n",
        "    return tokenizer.pad(examples, return_tensors='pt')\n",
        "\n",
        "train_dataset = QADataset(train_data, tokenizer)\n",
        "train_iter = DataLoader(dataset=QADataset(train_data, tokenizer),\n",
        "                        batch_size=4, collate_fn=collate_fn)\n",
        "dev_iter = DataLoader(dataset=QADataset(dev_data, tokenizer),\n",
        "                        batch_size=8, collate_fn=collate_fn)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfB9-yypwrGw",
        "outputId": "6682a592-c580-4657-9f6a-a4bcae6b5971"
      },
      "source": [
        "next(iter(train_iter))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,   511, 38300,  ..., 31399,   136,   102],\n",
              "        [  101, 11480, 17914,  ...,     0,     0,     0],\n",
              "        [  101,   526, 44169,  ...,     0,     0,     0],\n",
              "        [  101, 12624, 11657,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]]), 'start_positions': tensor([160,  34,  64,  98]), 'end_positions': tensor([199,  36,  66, 102])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ZGnrCRw6Mu"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSCPlIT-w4_H",
        "outputId": "0d31265d-4617-4e25-e38a-e94bf25bde13"
      },
      "source": [
        "comet_logger = CometLogger(\n",
        "    api_key=\"HWfJT3eyByVJWe4nEbi1pGosA\",\n",
        "    workspace=\"danildmitriev1999\",\n",
        "    project_name=\"qa\",\n",
        "    experiment_name=\"test\",\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CometLogger will be initialized in online mode\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOOlF5Dw-K1"
      },
      "source": [
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "QAModel = QA2Linear('bert-base-multilingual-cased').to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "model_trainer = ModelTrainer(QAModel, criterion).to(device)\n",
        "\n",
        "trainer = Trainer(max_epochs=N_EPOCHS,\n",
        "                gpus=1,\n",
        "                gradient_clip_val=CLIP,\n",
        "                progress_bar_refresh_rate=1,\n",
        "                log_every_n_steps=3,\n",
        "                logger=[comet_logger],\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTVY4NWTxFeV"
      },
      "source": [
        "trainer.fit(model_trainer, train_iter, dev_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlZrFEw-xaAm"
      },
      "source": [
        "# Тест"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcJugmsUxWN6"
      },
      "source": [
        "def predict(dt, n, model):\n",
        "    text = torch.tensor([val_dataset[n]['input_ids']]).to(device)\n",
        "    mask = torch.tensor([val_dataset[n]['attention_mask']]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        lg_start, lg_end = model(text, mask)\n",
        "\n",
        "    start_pred = torch.argmax(lg_start, dim=1).squeeze(-1).cpu().detach().numpy()[0]\n",
        "    end_pred = torch.argmax(lg_end, dim=1).squeeze(-1).cpu().detach().numpy()[0]\n",
        "\n",
        "    print(f\"gold position: {val_dataset[n]['start_positions'], val_dataset[n]['end_positions']}\")\n",
        "    print(f'position predict: {start_pred, end_pred}')\n",
        "\n",
        "    print(f\"gold: {tokenizer.decode(val_dataset[n]['input_ids'][val_dataset[n]['start_positions']: val_dataset[n]['end_positions']+1])}\")\n",
        "    print(f\"predict: {tokenizer.decode(val_dataset[n]['input_ids'][start_pred: end_pred+1])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2k_NmwJxdxX"
      },
      "source": [
        "val_dataset = QADataset(dev_data, tokenizer)\n",
        "trained_model = model_trainer.model\n",
        "trained_model = trained_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9M8hV1txdsJ"
      },
      "source": [
        "dev_data[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vL80ZzPxdnq"
      },
      "source": [
        "predict(dev_data, 5, trained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk0sBVUfxdjL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZntorFpxdYH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}